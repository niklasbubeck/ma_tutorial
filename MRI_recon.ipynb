{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercise4_MRI.ipynb","provenance":[{"file_id":"1ZTqgBqBENyJ6y4IkiXKcv9Pdu-KdCnK9","timestamp":1655295075099},{"file_id":"https://github.com/khammernik/AI4doctors/blob/master/AI4doctors_inverse_problems.ipynb","timestamp":1655277674299}],"collapsed_sections":["3FQfPO7E4wTw","Prqq7W7pUt9p","izcaa68j5-Qa"],"authorship_tag":"ABX9TyNvDAtEf/07CWHhT+uPcLF9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction\n","\n","In this exercise, you will get introduced to the world of MRI reconstruction. We start with examining the raw k-space data and coil-sensitivity maps and build the multi-coil forward and adjoint operator. Additionally, we solve a linear and a regularized reconstruction problem, which allows us to deeply understand where we can later connect to machine learning.\n","\n","First, we install the dependencies and download the data."],"metadata":{"id":"3FQfPO7E4wTw"}},{"cell_type":"code","source":["# install dependencies\n","!pip install PyWavelets git+https://github.com/khammernik/medutils.git"],"metadata":{"id":"FMZis3rdoWvf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# download data\n","!wget -O brain_cartesian_2D.h5 https://www.dropbox.com/s/hclfv3re91qb1v3/brain_cartesian_2D.h5?dl=1\n"],"metadata":{"id":"jbO9aJ7m4kq7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download ESPIRiT code for coil sensitivity map estimation\n","!git clone https://github.com/mikgroup/espirit-python.git\n","!cp /content/espirit-python/espirit.py ."],"metadata":{"id":"8ezeGwAE3ePu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Magnetic Resonance Image (MRI) Reconstruction\n","\n","The goal is to recover the clean image $x$, which is obtained by undersampled k-space data $y$ and corrupted by additive Gaussian white noise $n$,\n","$$ y = Ax + n. $$\n","The rawdata $y$ was aquired for multiple receive coils. The linear operator $A$ denotes the mapping from image space to k-space.\n"],"metadata":{"id":"rN6i2t_WSAjw"}},{"cell_type":"markdown","source":["## Data Loading\n","\n","In the first step, we examine the avaiable data regarding their shape and their datatype. Note, that we are dealing with complex-valued data here."],"metadata":{"id":"PIA9scmCZAsd"}},{"cell_type":"code","source":["import h5py\n","import numpy as np\n","import medutils\n","np.random.seed(1001)\n","\n","ds = h5py.File('./brain_cartesian_2D.h5', 'r')\n","kspace = ds['kspace'][()]\n","ds.close()\n","\n","print(f'K-Space:')\n","print(f'dtype={kspace.dtype}')\n","print(f'(nCoils, nFE, nPE)={kspace.shape}')\n","nCoils, nFE, nPE = kspace.shape"],"metadata":{"id":"eNj1r9CqS8Mh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We observe that we have 16 coils, the number of frequency encoding (readout) points `nFE` equals 640, and the number of phase encoding steps `nPE` is 330. We will come back to this later."],"metadata":{"id":"w_UitpW8VRdG"}},{"cell_type":"markdown","source":["## Data Visualization\n","For data visualization, you are free to use any plotting library such as `matplotlib` or use the provided `medutils` package. The `medutils` package has some useful function for visualization:\n","- `kshow` Process the data in log-space\n","- `imshow` Display the magnitude of the image\n","- `plot_array` Re-arrange the images from a 3D array next to each other.\n","- `ksave` Save k-space\n","- `imsave` Save images\n","\n","We will first visualize the `kspace`."],"metadata":{"id":"Prqq7W7pUt9p"}},{"cell_type":"code","source":["medutils.visualization.kshow(medutils.visualization.plot_array(kspace, M=2, N=8), title='K-space', figsize=(40,20))"],"metadata":{"id":"CO2e_OvXUwLV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Transforming k-space to image space\n","Let us now start to transform the `kspace` to images. Therefore, we require the centered 2d inverse Fourier transform. Application of the `ifft2c` to the k-space results in single coil images.\n","\n","**Task 1: Write the function `ifft2c(kspace)`**"],"metadata":{"id":"mt6WTnNqXq9b"}},{"cell_type":"code","source":["def ifft2c(kspace):\n","  #TODO implement the centered inverse FFT.\n","  return None\n","\n","coil_img = ifft2c(kspace)\n","medutils.visualization.imshow(medutils.visualization.plot_array(coil_img, M=2, N=8), title='Coil Images', figsize=(40,20))"],"metadata":{"id":"_zD9fi0BVzvi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You might notice several things. First, you see that only a fraction of the image is bright. This is due to the effect that the coils are sensitive only in a certain spatial region. Second, you might notice that there are a lot of black areas all over the image, especially in y direction. This extended field of view in read-out direction, also termed frequency-encoding direction is actually for free, does not cost any additional acquisition time, and is implemented per default on MRI scanners.  Assuming the base resolution is 320, the number of frequency encoding steps is doubled. This frequency oversampling results in an increased field-of-view in this direction. After the image is transformed to image domain, only the central part needs to be visualized. However, for display, we will from now on only consider the central part."],"metadata":{"id":"Em5MdDLkYBYy"}},{"cell_type":"markdown","source":["## Root-Sum-of-Squares Reconstruction\n","\n","Now, we calculate the Root-Sum-of-Squares reconstruction $x_{rss}$\n","$$ x_{rss} = \\sqrt{ \\sum_{c=1}^{nCoils} \\vert x_c \\vert ^ 2 }, $$\n","\n","where $x_c$ are the individual coil images. Note that using the root-sum-of-squares reconstruction, the phase information of the complex-valued data gets lost. \n","\n","We now visualize only the central part of the reconstructed image of size `[nFE//2, nPE]`. \n","\n","**Task 2: Implement the RSS reconstruction `rss(coil_img)`**"],"metadata":{"id":"6kbOdgVwUG1I"}},{"cell_type":"code","source":["def rss(coil_img):\n","  #TODO implement the rss reconstruction\n","  return None\n","\n","x_rss = rss(coil_img)\n","medutils.visualization.imshow(medutils.visualization.center_crop(x_rss, (nFE//2, nPE)), figsize=(10,10), title='RSS reconstruction')"],"metadata":{"id":"qeYHaNA7VZXt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Coil Compression using an SVD\n","The number of receive coils play an important role in accelerated parallel imaging in order to receive high-quality images. However, the larger the number of coils, the more memory the dataset requires and the more computationally expensive the computations are. Coil compression provides a way to reduce the dataset to a smaller number of $P$ virtual coils [1-3]. Let us define the original k-space as $y$, and the compressed k-space as $y_P$. The compressed k-space can be determined by applying a compression matrix $T$ to $y$\n","$$ y_P = T y. $$\n","To form our compression matrix $T$, we first apply a pixel-wise SVD to the k-space data,\n","$$y = USV^\\top,$$\n","where $U$ and $V$ denote the left and right singular vectors and $S$ the diagonal matrix of singular values. To form the compression matrix $T$, we only keep the singular vectors that correspond to the $P$ largest singular values. Hence, the compressed k-space is computed as\n","$$\n","y_P = U_p y.\n","$$\n","\n","\n","**Task 3: Implement `coil_compression(kspace, svd_cutoff=0.15)`. The parameter `svd_cutoff` defines a threshold for the singular values, i.e., only singular vectors with a corresponding singular value**\n","$$\\frac{\\sigma_i}{\\sigma_{max}} \\geq \\text{svd\\_cutoff}$$ \n","\n","**should be kept. Compute and print the number of virtual coils and return the reduced k-space $y_p$.**\n","\n","*Hint: Think about the size of $y$ that should go to the SVD. You do not need to store `full_matrices`. Also think about the matrix sizes for $U$, $S$, and $U_p$. The returned k-space should again have a size of `[nCoils_svd, nFE, nPE]`.*\n","\n","\n","**Reference**\n","\n","[1] Huang et al. [A software channel compression technique for faster reconstruction with many channels](https://www.sciencedirect.com/science/article/pii/S0730725X07002731). Magn Reson Imaging 26(1):133-141, 2008.\n","\n","[2] Buehrer et al. [Array compression for MRI with large coil arrays](https://onlinelibrary.wiley.com/doi/10.1002/mrm.21237). Magn Reson Med 57:1131-1139, 2007.\n","\n","[3] Zhang et al. [Coil compression for accelerated imaging with Cartesian sampling](https://onlinelibrary.wiley.com/doi/10.1002/mrm.24267). Magn Reson Med 69:571-582, 2013.\n"],"metadata":{"id":"XVSNSP3DurY1"}},{"cell_type":"code","source":["def coil_compression(kspace, svd_cutoff=0.15):\n","  # TODO implement coil compression\n","  return kspace\n","\n","kspace = coil_compression(kspace)"],"metadata":{"id":"6Lx-V7ARuqll"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we will visualize again the (compressed) coil images and the RSS reconstruction."],"metadata":{"id":"au3m_Bgyj7DV"}},{"cell_type":"code","source":["coil_img = ifft2c(kspace)\n","medutils.visualization.imshow(medutils.visualization.plot_array(medutils.visualization.center_crop(coil_img, (nFE//2, nPE))), title='Coil Images (compressed)', figsize=(20,10))"],"metadata":{"id":"e6owYqvXXVwd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_rss = rss(coil_img)\n","medutils.visualization.imshow(medutils.visualization.center_crop(x_rss, (320,320)), title='RSS reconstruction (compressed)', figsize=(10,10))"],"metadata":{"id":"WE7r2-SkYGWh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Sensitivity Map Estimation\n","\n","The coil sensitivity maps (`smaps`) are smooth maps that show us in which parts the single coil elements are sensitive. We will need these information for our multi-coil MRI forward and adjoint operators. We use the [python implementation](https://github.com/mikgroup/espirit-python) for ESPIRiT [4,5] to estimate these coil sensitivity maps.\n","\n","[4] Uecker et al. [ESPIRiTâ€”an eigenvalue approach to autocalibrating parallel MRI: Where SENSE meets GRAPPA](https://onlinelibrary.wiley.com/doi/10.1002/mrm.24751). Magn Reson Med 71(3):990-1001, 2014.\n","\n","[5] https://github.com/mikgroup/espirit-python"],"metadata":{"id":"izcaa68j5-Qa"}},{"cell_type":"code","source":["import espirit\n","kspace_espirit = np.transpose(kspace, (1, 2, 0))[:,:,np.newaxis]\n","smaps_espirit = espirit.espirit(kspace_espirit, 8, 24, 0.05, 0)\n","\n","smaps = smaps_espirit[:,:,0,:,0]\n","smaps = np.transpose(smaps, (2, 0, 1))"],"metadata":{"id":"YP1mGhS559Zu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let us visualize the coil sensitivity maps for our compressed k-space."],"metadata":{"id":"dQR3u1zulY9k"}},{"cell_type":"code","source":["medutils.visualization.imshow(medutils.visualization.plot_array(smaps), title='Sensitivity Maps  (compressed)', figsize=(40,20))"],"metadata":{"id":"OS7HflObXC--"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Multi-Coil Operators and Sensitivity-Weighted coil combination\n","\n","Now, we have all ingredients to combine the image! Do you remember how the forward and adjoint MRI multi-coil operators are defined? These are required in the next steps.\n","\n","**Task 4: Implement the multi-coil forward operator $A$ in `mriForwardOp(image, smaps, mask)` and adjoint operator $A^*$ in `mriAdjointOp(kspace, smaps, mask)`. Please check the lecture slides for details on the implementation.**\n","\n","*Hint: Start with the implementation of the adjoint operator and make use of the previously written function `ifft2c`. Then, define a function `fft2c` which is the 2D centered Fourier transform before you continue with the forward operator.*\n","\n","## Suggested Readings:\n","\n","Pruessmann et al. [SENSE: Sensitivity encoding for fast MRI](https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291522-2594%28199911%2942%3A5%3C952%3A%3AAID-MRM16%3E3.0.CO%3B2-S) Magnetic Resonance in Medicine, 43(5):952-962, 1999.\n"],"metadata":{"id":"tSEJEA8GZEqK"}},{"cell_type":"code","source":["def mriAdjointOp(kspace, smaps, mask):\n","  # TODO implement\n","  return None\n","\n","def fft2c(image):\n","  # TODO implement\n","  return None\n","\n","def mriForwardOp(image, smaps, mask):\n","  # TODO implement\n","  return None"],"metadata":{"id":"Xxwj3aQBYpVi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, you should check if the adjoint operator is working as expected. The result should be a coil-combined image. Right now, there is no undersampling mask involved, i.e., it is set to all ones."],"metadata":{"id":"yo1OdsSInbKG"}},{"cell_type":"code","source":["img_cc = mriAdjointOp(kspace, smaps, np.ones_like(kspace))\n","medutils.visualization.imshow(medutils.visualization.center_crop(img_cc, (nFE//2, nPE)), title='Combined image (sensitivity-weighted)', figsize=(8,8))"],"metadata":{"id":"owqzxb74nVqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Task 5: Adjointness check**\n","\n","Now, also check if the operators are adjoint using following equation:\n","$$ \\langle Au, v\\rangle = \\langle u, A^*v\\rangle,$$\n","where $u$ and $v$ are complex random numbers. Think about which sizes $u$ and $v$ should have. Note, that the sampling mask and sensitivity maps are kept constant. To create random numbers, use `np.random.randn`. Print the results for the left-hand side and right-hand side of the equation.\n","\n","*Hint: To get the correct result, you might use the `conj` when computing the complex-valued dot product.*"],"metadata":{"id":"kf3LX-qSn5SP"}},{"cell_type":"code","source":["# TODO implement the adjointness check"],"metadata":{"id":"17WwxyIrn4gm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Undersampling\n","Now we will get to the most exciting part of this exercise - undersampling the k-space! We will generate undersampling masks for acceleration $R\\in\\lbrace 2,3\\rbrace$. \n","\n","**Task 5: Your task is to play around with different undersampling patterns. Generate a sampling pattern in the function `generate_mask(R, nPE, nFE, mode)` where `R` is the acceleration factor and `mode` is an integer corresponding to following patterns:**\n","1. Choose randomly an integer [0,1] with propability `p=[1/R, 1-1/R]`\n","2. Only set a dense block of `nRef=20` lines in the center of k-space.\n","3. Combine 1.+2.\n","4. Only set every `R`-th line\n","5. Combine 2.+4. \n","\n","To create the mask, simply generate a 1D line of size `nPE`. For each item, compute and print the effective acceleration `Reff`, which is determined by `nPE` divided by the number of sampled points. \n","\n","The code to get the full mask of size `[nFE, nPE]` is given below.\n","\n","To continue the tasks on iterative reconstruction, please use `mode=3` and `R=3` as well as `mode=5` and `R=3`."],"metadata":{"id":"L0Fv8DY7ZxaZ"}},{"cell_type":"code","source":["# TODO generate undersampling masks\n","def generate_mask(R, nPE, nFE, mode):\n","  mask = np.ones(nPE)\n","\n","  mask = mask.reshape(1, nPE).repeat(nFE, axis=0)\n","\n","  return mask"],"metadata":{"id":"08GrS1rcZw6W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, generate the mask and visualize it (we visualize only a fraction in frequency encoding direction)."],"metadata":{"id":"qIyzXD39zKQo"}},{"cell_type":"code","source":["np.random.seed(1001)\n","mask = generate_mask(R=3, nPE=nPE, nFE=nFE, mode=5)\n","\n","medutils.visualization.imshow(mask[:40,:], 'Undersampling mask', figsize=(20,20))"],"metadata":{"id":"9nTeENqRzGig"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Task 6: Zero-Filling solution**\n","\n","Now you are ready to estimate the zero filling solution by applying the adjoint operator to the data, by using the estimated undersampling mask `mask`. Play around with above mask configurations. How do the images change?"],"metadata":{"id":"0zy-F7VAcHYR"}},{"cell_type":"code","source":["#TODO Apply the adjoint operator to the data and use the newly created undersampling mask.\n","img_cc_us = None\n","img_cc_us = medutils.visualization.center_crop(img_cc_us, (nFE//2, nPE))\n","medutils.visualization.imshow(img_cc_us, 'Undersampled image (zero filling)', figsize=(10,10))"],"metadata":{"id":"XFdaATXDb0E-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Linear and Regularized Reconstruction\n","Now, we are ready to implement linear and regularized reconstruction. We additionally need the gradient operator, implementing forward / backward differences in `D` and `DT`, and the multi-coil MRI forward and adjoint operators, `A` and `AH`, respectively."],"metadata":{"id":"zFKJhOEBchbF"}},{"cell_type":"code","source":["def nabla(x):\n","    dx = np.pad(x[:,1:], [[0, 0],[0, 1]], mode='edge')\n","    dy = np.pad(x[1:], [[0, 1],[0, 0]], mode='edge')\n","    return np.concatenate([dx[None,...] - x, dy[None,...] - x], 0)\n","\n","def nablaT(x):\n","    assert x.shape[0] == 2\n","    dx = np.pad(x[0,:,:-1], [[0, 0],[1, 0]], mode='constant')\n","    dy = np.pad(x[1,:-1], [[1, 0],[0, 0]], mode='constant')\n","    return dx - x[0] + dy - x[1] \n","\n","D = lambda x: nabla(np.real(x)) + 1j * nabla(np.imag(x))\n","DT= lambda x: nablaT(np.real(x)) + 1j * nablaT(np.imag(x))"],"metadata":{"id":"XM58ogWNc4M6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["A = lambda x: mriForwardOp(x, smaps, mask)\n","AH = lambda x: mriAdjointOp(x, smaps, mask)"],"metadata":{"id":"anJOsdUec7cz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Solving the linear reconstruction problem\n","Consider the following minimization problem:\n","\n","$$ \\min_x  E(x,y) = \\min_x \\frac{1}{2} \\Vert Ax - y \\Vert_2^2 .$$\n","\n","While in image denoising we are still able to compute a closed-form solution for this problem, this is not feasible for the task of MRI reconstruction anymore. We instead use first-order optimization methods and solve this by Gradient Descent:\n","$$ x^{t+1} = x^{t} - \\alpha \\nabla_x E(x,y) $$\n","$$ x^{t+1} = x^{t} - \\alpha A^* (Ax^t - y) $$\n","\n","**Task 6: Implement Gradient Descent in `opt_linear` to solve the linear reconstruction problem and run the optimization for `max_iter=50` iterations and a step size of `alpha=1`**"],"metadata":{"id":"oiFZ3aR7dT_O"}},{"cell_type":"code","source":["def opt_linear(y, max_iter, alpha):\n","    x = np.zeros_like(AH(y))\n","\n","    #TODO implement gradient descent to solve the linear reconstruction problem\n","    return x"],"metadata":{"id":"d2h7OIo1dN64"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpha=1\n","img_linear = opt_linear(kspace, max_iter=50, alpha=alpha)\n","img_linear = medutils.visualization.center_crop(img_linear, (nFE//2, nPE))\n","medutils.visualization.imshow(img_linear, f'Linear reconstruction alpha={alpha}', figsize=(10,10))"],"metadata":{"id":"zTkILw7GeOEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## L2-H1 Regularization\n","\n","Now, we regularize the least-squares problem with a regularizer of form $\\mathcal{R}(x)=\\frac{1}{2} \\Vert \\nabla x \\Vert_2^2$.\n","Consider now the following minimization problem\n","\n","$$ \\min_x  D(x,y) + \\lambda R(x) = \\min_x \\frac{1}{2}\\Vert Ax - y \\Vert_2^2 + \\frac{\\lambda}{2}\\Vert \\nabla x \\Vert_2^2.$$\n","\n","We solve this by Gradient Descent:\n","$$ x^{t+1} = x^{t} - \\alpha \\left( \\nabla_x D(x,y) + \\nabla_x R(x) \\right) $$\n","$$ x^{t+1} = x^{t} - \\alpha \\left( A^H (Ax^t - y) + \\lambda \\nabla^T \\nabla x \\right) $$\n","\n","**Task 7: Implement gradient descent to solve the L2-H1 regularized problem and run the optimization for `max_iter=200` iterations, a step size of `alpha=1.0` and a regularization parameter of `lambd=0.01`.**\n","\n","*Note that we do not have the best setting for the parameters here and the difference to the linear reconstruction might be only minimal. You can play around with the hyper-parameters. This example is to show you the properties of L2-H1 regularization and that it is actually hard to find a good set of hyper-parameters (step size, regularization parameters, iterations).*"],"metadata":{"id":"ziFJr1Mpe0re"}},{"cell_type":"code","source":["def opt_reg_l2(y, max_iter, alpha, lambd):\n","    x = np.zeros_like(AH(y))\n","    \n","    # TODO implement gradient descent for L2-H1 regularization\n","    return x"],"metadata":{"id":"OIk8_dJJe0N8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpha = 1.0\n","lambd = 0.01\n","img_reg_l2 = opt_reg_l2(kspace, max_iter=200, alpha=alpha, lambd=lambd)\n","img_reg_l2 = medutils.visualization.center_crop(img_reg_l2, (nFE//2, nPE))\n","medutils.visualization.imshow(img_reg_l2, f'L2H1 reconstruction alpha={alpha} lambda={lambd}', figsize=(10,10))"],"metadata":{"id":"6rDK8F2Ie1gO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Sparse MRI: Wavelet Thresholding\n","Medical images per se are not sparse, however, they might have a sparse representation in some transform domain. One example here is the Wavelet transform, resulting in a multi-level feature representation. We provide the `plot_wavedec` function to find out how the sparse images look like at different scales and orientations.\n","\n","We perform an optimization first wrt. data consistency term. This is followed by a Wavelet transform, and the *detailed* Wavelet coefficients are surpressed by using soft-thresholding, i.e.,\n","\n","$$\n","\\text{thresh}(x) = \\frac{x}{\\vert x \\vert}\\max(\\vert x \\vert - \\alpha\\lambda , 0)\n","$$\n","\n","**Task 8: Implement the soft-thresholding in `soft_thresh(x, tau)`**\n","\n","*Hint: Note, that the absolut value could get zero, and a small epsilon might be adorable to surpress this.*\n","\n","### Suggested Readings\n","\n","Lustig et al. [Compressed Sensing MRI](https://ieeexplore.ieee.org/document/4472246), IEEE Signal Processing Magazine 25(2):72-82, 2008.\n","\n","Lustig et al. [Sparse MRI: The application of compressed sensing for rapid MR imaging](https://onlinelibrary.wiley.com/doi/full/10.1002/mrm.21391). Magnetic Resonance in Medicine 58(6):1182-1195, 2007."],"metadata":{"id":"DgHKKicfgExG"}},{"cell_type":"code","source":["def soft_thresh(x, tau):\n","    #TODO: implement soft-thresholding\n","    return None"],"metadata":{"id":"17LiCd6A_MOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pywt\n","\n","def plot_wavedec(img, wavelet='db4', level=2):\n","    img = medutils.visualization.center_crop(img_cc, (nFE//2, nPE))\n","    coeffs = pywt.wavedecn(img, wavelet=wavelet, level=level)\n","    # normalize coeffs\n","    coeffs[0] /= np.max(np.abs(coeffs[0]))\n","    for level in range(1, len(coeffs)):\n","        for key in coeffs[level].keys():\n","            coeffs[level][key] /= np.max(np.abs(coeffs[level][key]))\n","    arr, coeff_slices = pywt.coeffs_to_array(coeffs)\n","    medutils.visualization.imshow(arr, figsize=(10,10))\n","\n","def opt_reg_wavelet(y, max_iter, alpha, lambd, wavelet='db4', level=3):\n","    x = np.zeros_like(AH(y))\n","    wavelet_object = pywt.Wavelet(wavelet)\n","    threshold = alpha * lambd\n","\n","    for _ in range(max_iter):\n","        x = x - alpha * (AH(A(x) - y))\n","        coeffs = pywt.wavedecn(x, wavelet_object, level=level)\n","        array, coeff_slices = pywt.coeffs_to_array(coeffs)\n","        denoised_array=soft_thresh(array, threshold)\n","        denoised_coeffs = pywt.array_to_coeffs(denoised_array, coeff_slices, output_format='wavedecn')\n","        denoised_coeffs[0] = coeffs[0]\n","        x = pywt.waverecn(denoised_coeffs, wavelet_object)\n","        \n","    return x"],"metadata":{"id":"nIeuyuFtgEMm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next, we define a wavelet, the number of levels for decomposition and plot the decomposition."],"metadata":{"id":"DlHCMCmB_ECn"}},{"cell_type":"code","source":["# Plot Wavelet Decomposition\n","wavelet='bior2.8'\n","level=3\n","plot_wavedec(img_cc, wavelet, level)"],"metadata":{"id":"W2RfjPmygfCw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, we run the optimization for `lambd=1e-6` and `alpha=1` and 200 iterations."],"metadata":{"id":"HaB2pREX_Y0j"}},{"cell_type":"code","source":["lambd=1e-6\n","alpha=1.0\n","img_reg_wavelet = opt_reg_wavelet(kspace, max_iter=200, alpha=alpha, lambd=lambd, wavelet=wavelet, level=level)\n","img_reg_wavelet = medutils.visualization.center_crop(img_reg_wavelet, (nFE//2, nPE))\n","medutils.visualization.imshow(img_reg_wavelet, f'Wavelet reconstruction alpha={alpha} lambda={lambd}', figsize=(10,10))"],"metadata":{"id":"wnDICemEgub_"},"execution_count":null,"outputs":[]}]}